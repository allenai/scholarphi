{"format_version": "v0", "data": [{"id_": "abdelhamid2012-0", "type_": "citation", "bounding_boxes": [{"left": 0.7075163398692811, "top": 0.37626262626262624, "width": 0.0016339869281045752, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "abdelhamid2012-0"}], "data": {"key": "abdelhamid2012", "bibitem_text": "O.~Abdel-Hamid, A.-r. Mohamed, H.~Jang, and G.~Penn. Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition. In \\em ICASSP , 2012.", "paper_id": "9a9f4bf3bfe133e1c70f6b60654c238b677c66d0", "corpus_id": "10042024"}, "relationships": null}, {"id_": "abdelhamid2012-1", "type_": "citation", "bounding_boxes": [{"left": 0.5882352941176471, "top": 0.6906565656565656, "width": 0.0016339869281045752, "height": 0.008838383838383838, "page": 8, "tex_path": "N/A", "entity_id": "abdelhamid2012-1"}], "data": {"key": "abdelhamid2012", "bibitem_text": "O.~Abdel-Hamid, A.-r. Mohamed, H.~Jang, and G.~Penn. Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition. In \\em ICASSP , 2012.", "paper_id": "9a9f4bf3bfe133e1c70f6b60654c238b677c66d0", "corpus_id": "10042024"}, "relationships": null}, {"id_": "bahdanau2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.33169934640522875, "top": 0.5227272727272727, "width": 0.004901960784313725, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "bahdanau2015-0"}], "data": {"key": "bahdanau2015", "bibitem_text": "D.~Bahdanau, K.~Cho, and Y.~Bengio. Neural machine translation by jointly learning to align and translate. In \\em ICLR , 2015.", "paper_id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "corpus_id": "11212020"}, "relationships": null}, {"id_": "bahdanau2015-1", "type_": "citation", "bounding_boxes": [{"left": 0.4722222222222222, "top": 0.5517676767676768, "width": 0.004901960784313725, "height": 0.008838383838383838, "page": 7, "tex_path": "N/A", "entity_id": "bahdanau2015-1"}], "data": {"key": "bahdanau2015", "bibitem_text": "D.~Bahdanau, K.~Cho, and Y.~Bengio. Neural machine translation by jointly learning to align and translate. In \\em ICLR , 2015.", "paper_id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "corpus_id": "11212020"}, "relationships": null}, {"id_": "bahdanau2015b-0", "type_": "citation", "bounding_boxes": [{"left": 0.4624183006535948, "top": 0.5366161616161617, "width": 0.006535947712418301, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "bahdanau2015b-0"}], "data": {"key": "bahdanau2015b", "bibitem_text": "D.~Bahdanau, J.~Chorowski, D.~Serdyuk, P.~Brakel, and Y.~Bengio. End-to-end attention-based large vocabulary speech recognition. abs/1508.04395, 2015. http://arxiv.org/abs/1508.04395.", "paper_id": "878ba5458e9e51f0b341fd9117fa0b43ef4096d3", "corpus_id": "11760007"}, "relationships": null}, {"id_": "barker2015chime-0", "type_": "citation", "bounding_boxes": [{"left": 0.32516339869281047, "top": 0.8712121212121212, "width": 0.006535947712418301, "height": 0.008838383838383838, "page": 8, "tex_path": "N/A", "entity_id": "barker2015chime-0"}], "data": {"key": "barker2015chime", "bibitem_text": "J.~Barker, E.~Marxer, Ricard~Vincent, and S.~Watanabe. The third 'CHiME' speech separation and recognition challenge: Dataset, task and baselines. 2015. Submitted to IEEE 2015 Automatic Speech Recognition and Understanding Workshop (ASRU).", "paper_id": "eadf5023c90a6af8a0f8e8605bd8050cc13c23a3", "corpus_id": "4397499"}, "relationships": null}, {"id_": "barker2015chime-1", "type_": "citation", "bounding_boxes": [{"left": 0.4199346405228758, "top": 0.672979797979798, "width": 0.006535947712418301, "height": 0.008838383838383838, "page": 18, "tex_path": "N/A", "entity_id": "barker2015chime-1"}], "data": {"key": "barker2015chime", "bibitem_text": "J.~Barker, E.~Marxer, Ricard~Vincent, and S.~Watanabe. The third 'CHiME' speech separation and recognition challenge: Dataset, task and baselines. 2015. Submitted to IEEE 2015 Automatic Speech Recognition and Understanding Workshop (ASRU).", "paper_id": "eadf5023c90a6af8a0f8e8605bd8050cc13c23a3", "corpus_id": "4397499"}, "relationships": null}, {"id_": "ModernGPU-0", "type_": "citation", "bounding_boxes": [{"left": 0.6601307189542484, "top": 0.5896464646464646, "width": 0.006535947712418301, "height": 0.008838383838383838, "page": 13, "tex_path": "N/A", "entity_id": "ModernGPU-0"}], "data": {"key": "ModernGPU", "bibitem_text": "S.~Baxter. Modern GPU. https://nvlabs.github.io/moderngpu/."}, "relationships": null}, {"id_": "ModernGPU-1", "type_": "citation", "bounding_boxes": [{"left": 0.23039215686274508, "top": 0.7032828282828283, "width": 0.006535947712418301, "height": 0.008838383838383838, "page": 26, "tex_path": "N/A", "entity_id": "ModernGPU-1"}], "data": {"key": "ModernGPU", "bibitem_text": "S.~Baxter. Modern GPU. https://nvlabs.github.io/moderngpu/."}, "relationships": null}, {"id_": "bengio2009curriculum-0", "type_": "citation", "bounding_boxes": [{"left": 0.8104575163398693, "top": 0.7310606060606061, "width": 0.008169934640522876, "height": 0.008838383838383838, "page": 6, "tex_path": "N/A", "entity_id": "bengio2009curriculum-0"}], "data": {"key": "bengio2009curriculum", "bibitem_text": "Y.~Bengio, J.~Louradour, R.~Collobert, and J.~Weston. Curriculum learning. In \\em International Conference on Machine Learning , 2009.", "paper_id": "8de174ab5419b9d3127695405efd079808e956e8", "corpus_id": "873046"}, "relationships": null}, {"id_": "bourlard93-0", "type_": "citation", "bounding_boxes": [{"left": 0.6519607843137255, "top": 0.32196969696969696, "width": 0.006535947712418301, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "bourlard93-0"}], "data": {"key": "bourlard93", "bibitem_text": "H.~Bourlard and N.~Morgan. \\em Connectionist Speech Recognition: A Hybrid Approach. Kluwer Academic Publishers, Norwell, MA, 1993.", "paper_id": "3d82e058a5c40954b8f5db170a298a889a254c37", "corpus_id": "61058350"}, "relationships": null}, {"id_": "chan2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.4803921568627451, "top": 0.5366161616161617, "width": 0.004901960784313725, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "chan2015-0"}], "data": {"key": "chan2015", "bibitem_text": "W.~Chan, N.~Jaitly, Q.~Le, and O.~Vinyals. Listen, attend, and spell. abs/1508.01211, 2015. http://arxiv.org/abs/1508.01211.", "paper_id": "dc555e8156c956f823587ebbff018863e6d2a95e", "corpus_id": "14177763"}, "relationships": null}, {"id_": "chan2015-1", "type_": "citation", "bounding_boxes": [{"left": 0.43300653594771243, "top": 0.5517676767676768, "width": 0.004901960784313725, "height": 0.008838383838383838, "page": 7, "tex_path": "N/A", "entity_id": "chan2015-1"}], "data": {"key": "chan2015", "bibitem_text": "W.~Chan, N.~Jaitly, Q.~Le, and O.~Vinyals. Listen, attend, and spell. abs/1508.01211, 2015. http://arxiv.org/abs/1508.01211.", "paper_id": "dc555e8156c956f823587ebbff018863e6d2a95e", "corpus_id": "14177763"}, "relationships": null}, {"id_": "chetlur14-0", "type_": "citation", "bounding_boxes": [{"left": 0.5081699346405228, "top": 0.7171717171717171, "width": 0.008169934640522876, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "chetlur14-0"}], "data": {"key": "chetlur14", "bibitem_text": "S.~Chetlur, C.~Woolley, P.~Vandermersch, J.~Cohen, J.~Tran, B.~Catanzaro, and E.~Shelhamer. cuDNN: Efficient primitives for deep learning.", "paper_id": "31c36d445367ba204244bb74893c5654e31c3869", "corpus_id": "12330432"}, "relationships": null}, {"id_": "chilimbi2014adam-0", "type_": "citation", "bounding_boxes": [{"left": 0.6274509803921569, "top": 0.5580808080808081, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 1, "tex_path": "N/A", "entity_id": "chilimbi2014adam-0"}], "data": {"key": "chilimbi2014adam", "bibitem_text": "T.~Chilimbi, Y.~Suzue, J.~Apacible, and K.~Kalyanaraman. Project adam: Building an efficient and scalable deep learning training system. In \\em USENIX Symposium on Operating Systems Design and Implementation , 2014.", "paper_id": "e69c8b5df8a4178b1c8c7f154a761147a6f030be", "corpus_id": "2185117"}, "relationships": null}, {"id_": "cho2014-0", "type_": "citation", "bounding_boxes": [{"left": 0.7026143790849673, "top": 0.494949494949495, "width": 0.00980392156862745, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "cho2014-0"}], "data": {"key": "cho2014", "bibitem_text": "K.~Cho, B.~Van~Merrienboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares, H.~Schwenk, and Y.~Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In \\em EMNLP , 2014.", "paper_id": "0b544dfe355a5070b60986319a3f51fb45d1348e", "corpus_id": "5590763"}, "relationships": null}, {"id_": "cho2014-1", "type_": "citation", "bounding_boxes": [{"left": 0.5490196078431373, "top": 0.6123737373737373, "width": 0.00980392156862745, "height": 0.008838383838383838, "page": 4, "tex_path": "N/A", "entity_id": "cho2014-1"}], "data": {"key": "cho2014", "bibitem_text": "K.~Cho, B.~Van~Merrienboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares, H.~Schwenk, and Y.~Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In \\em EMNLP , 2014.", "paper_id": "0b544dfe355a5070b60986319a3f51fb45d1348e", "corpus_id": "5590763"}, "relationships": null}, {"id_": "cho2014-2", "type_": "citation", "bounding_boxes": [{"left": 0.6519607843137255, "top": 0.7588383838383839, "width": 0.00980392156862745, "height": 0.008838383838383838, "page": 6, "tex_path": "N/A", "entity_id": "cho2014-2"}], "data": {"key": "cho2014", "bibitem_text": "K.~Cho, B.~Van~Merrienboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares, H.~Schwenk, and Y.~Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In \\em EMNLP , 2014.", "paper_id": "0b544dfe355a5070b60986319a3f51fb45d1348e", "corpus_id": "5590763"}, "relationships": null}, {"id_": "cho2014-3", "type_": "citation", "bounding_boxes": [{"left": 0.75, "top": 0.5656565656565656, "width": 0.00980392156862745, "height": 0.008838383838383838, "page": 7, "tex_path": "N/A", "entity_id": "cho2014-3"}], "data": {"key": "cho2014", "bibitem_text": "K.~Cho, B.~Van~Merrienboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares, H.~Schwenk, and Y.~Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In \\em EMNLP , 2014.", "paper_id": "0b544dfe355a5070b60986319a3f51fb45d1348e", "corpus_id": "5590763"}, "relationships": null}, {"id_": "chorowski2015firstresults-0", "type_": "citation", "bounding_boxes": [{"left": 0.3415032679738562, "top": 0.5366161616161617, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "chorowski2015firstresults-0"}], "data": {"key": "chorowski2015firstresults", "bibitem_text": "J.~Chorowski, D.~Bahdanau, K.~Cho, and Y.~Bengio. End-to-end continuous speech recognition using attention-based recurrent nn: First results. abs/1412.1602, 2015. http://arxiv.org/abs/1412.1602.", "paper_id": "47d2dc34e1d02a8109f5c04bb6939725de23716d", "corpus_id": "453615"}, "relationships": null}, {"id_": "cieri2004Fisher-0", "type_": "citation", "bounding_boxes": [{"left": 0.24836601307189543, "top": 0.26136363636363635, "width": 0.013071895424836602, "height": 0.007575757575757576, "page": 14, "tex_path": "N/A", "entity_id": "cieri2004Fisher-0"}], "data": {"key": "cieri2004Fisher", "bibitem_text": "C.~Cieri, D.~Miller, and K.~Walker. The Fisher corpus: a resource for the next generations of speech-to-text. In \\em LREC , volume~4, pages 69--71, 2004.", "paper_id": "74ec753c27a01e93380c148ba886f8e0317c61ee", "corpus_id": "8414900"}, "relationships": null}, {"id_": "coates2011icdar-0", "type_": "citation", "bounding_boxes": [{"left": 0.673202614379085, "top": 0.7941919191919192, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "coates2011icdar-0"}], "data": {"key": "coates2011icdar", "bibitem_text": "A.~Coates, B.~Carpenter, C.~Case, S.~Satheesh, B.~Suresh, T.~Wang, D.~J. Wu, and A.~Y. Ng. Text detection and character recognition in scene images with unsupervised feature learning. In \\em International Conference on Document Analysis and Recognition , 2011.", "paper_id": "12244deb997152492d96c6246ec21b2b9804800d", "corpus_id": "16657844"}, "relationships": null}, {"id_": "coates2013cotshpc-0", "type_": "citation", "bounding_boxes": [{"left": 0.2630718954248366, "top": 0.7310606060606061, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "coates2013cotshpc-0"}, {"left": 0.41830065359477125, "top": 0.7032828282828283, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "coates2013cotshpc-0"}], "data": {"key": "coates2013cotshpc", "bibitem_text": "A.~Coates, B.~Huval, T.~Wang, D.~J. Wu, A.~Y. Ng, and B.~Catanzaro. Deep learning with COTS HPC . In \\em International Conference on Machine Learning , 2013.", "paper_id": "d1208ac421cf8ff67b27d93cd19ae42b8d596f95", "corpus_id": "8604637"}, "relationships": null}, {"id_": "dahl2011-0", "type_": "citation", "bounding_boxes": [{"left": 0.7516339869281046, "top": 0.36237373737373735, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "dahl2011-0"}], "data": {"key": "dahl2011", "bibitem_text": "G.~Dahl, D.~Yu, and L.~Deng. Large vocabulary continuous speech recognition with context-dependent DBN-HMMs . In \\em Proc. ICASSP , 2011.", "paper_id": "2446e8f2012f23176ff602be633c0ed2b956d66c", "corpus_id": "6703261"}, "relationships": null}, {"id_": "dahl2011-1", "type_": "citation", "bounding_boxes": [{"left": 0.6143790849673203, "top": 0.5782828282828283, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 8, "tex_path": "N/A", "entity_id": "dahl2011-1"}], "data": {"key": "dahl2011", "bibitem_text": "G.~Dahl, D.~Yu, and L.~Deng. Large vocabulary continuous speech recognition with context-dependent DBN-HMMs . In \\em Proc. ICASSP , 2011.", "paper_id": "2446e8f2012f23176ff602be633c0ed2b956d66c", "corpus_id": "6703261"}, "relationships": null}, {"id_": "dahl2011a-0", "type_": "citation", "bounding_boxes": [{"left": 0.7254901960784313, "top": 0.36237373737373735, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "dahl2011a-0"}], "data": {"key": "dahl2011a", "bibitem_text": "G.~Dahl, D.~Yu, L.~Deng, and A.~Acero. Context-dependent pre-trained deep neural networks for large vocabulary speech recognition. \\em IEEE Transactions on Audio, Speech, and Language Processing, 2011.", "paper_id": "6658bbf68995731b2083195054ff45b4eca38b3a", "corpus_id": "14862572"}, "relationships": null}, {"id_": "dean2012largescale-0", "type_": "citation", "bounding_boxes": [{"left": 0.6045751633986928, "top": 0.5580808080808081, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 1, "tex_path": "N/A", "entity_id": "dean2012largescale-0"}], "data": {"key": "dean2012largescale", "bibitem_text": "J.~Dean, G.~S. Corrado, R.~Monga, K.~Chen, M.~Devin, Q.~Le, M.~Mao, M.~Ranzato, A.~Senior, P.~Tucker, K.~Yang, and A.~Ng. Large scale distributed deep networks. In \\em Advances in Neural Information Processing Systems 25 , 2012.", "paper_id": "3127190433230b3dc1abd0680bb58dced4bcd90e", "corpus_id": "372467"}, "relationships": null}, {"id_": "dean2012largescale-1", "type_": "citation", "bounding_boxes": [{"left": 0.4117647058823529, "top": 0.7310606060606061, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "dean2012largescale-1"}], "data": {"key": "dean2012largescale", "bibitem_text": "J.~Dean, G.~S. Corrado, R.~Monga, K.~Chen, M.~Devin, Q.~Le, M.~Mao, M.~Ranzato, A.~Senior, P.~Tucker, K.~Yang, and A.~Ng. Large scale distributed deep networks. In \\em Advances in Neural Information Processing Systems 25 , 2012.", "paper_id": "3127190433230b3dc1abd0680bb58dced4bcd90e", "corpus_id": "372467"}, "relationships": null}, {"id_": "dean2012largescale-2", "type_": "citation", "bounding_boxes": [{"left": 0.6421568627450981, "top": 0.19823232323232323, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 12, "tex_path": "N/A", "entity_id": "dean2012largescale-2"}], "data": {"key": "dean2012largescale", "bibitem_text": "J.~Dean, G.~S. Corrado, R.~Monga, K.~Chen, M.~Devin, Q.~Le, M.~Mao, M.~Ranzato, A.~Senior, P.~Tucker, K.~Yang, and A.~Ng. Large scale distributed deep networks. In \\em Advances in Neural Information Processing Systems 25 , 2012.", "paper_id": "3127190433230b3dc1abd0680bb58dced4bcd90e", "corpus_id": "372467"}, "relationships": null}, {"id_": "ellis1999-0", "type_": "citation", "bounding_boxes": [{"left": 0.696078431372549, "top": 0.32196969696969696, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "ellis1999-0"}], "data": {"key": "ellis1999", "bibitem_text": "D.~Ellis and N.~Morgan. Size matters: An empirical study of neural network training for large vocabulary continuous speech recognition. In \\em ICASSP , volume~2, pages 1013--1016. IEEE, 1999.", "paper_id": "acf4e90062ca28e12f9e3a8c8b117030469d3e4b", "corpus_id": "1196476"}, "relationships": null}, {"id_": "Elsen2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.5147058823529411, "top": 0.6590909090909091, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 21, "tex_path": "N/A", "entity_id": "Elsen2015-0"}], "data": {"key": "Elsen2015", "bibitem_text": "E.~Elsen. Optimizing RNN performance. http://svail.github.io/rnn_perf. Accessed: 2015-11-24."}, "relationships": null}, {"id_": "gales2009-0", "type_": "citation", "bounding_boxes": [{"left": 0.4084967320261438, "top": 0.8080808080808081, "width": 0.011437908496732025, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "gales2009-0"}], "data": {"key": "gales2009", "bibitem_text": "M.~J.~F. Gales, A.~Ragni, H.~Aldamarki, and C.~Gautier. Support vector machines for noise robust ASR . In \\em ASRU , pages 205--2010, 2009.", "paper_id": "a79469f93eb180f6b2227a8d511667028d1720cf", "corpus_id": "19022413"}, "relationships": null}, {"id_": "graves2006-0", "type_": "citation", "bounding_boxes": [{"left": 0.272875816993464, "top": 0.32196969696969696, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 1, "tex_path": "N/A", "entity_id": "graves2006-0"}], "data": {"key": "graves2006", "bibitem_text": "A.~Graves, S.~Fern\\'a ndez, F.~Gomez, and J.~Schmidhuber. Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In \\em ICML , pages 369--376. ACM, 2006.", "paper_id": "96494e722f58705fa20302fe6179d483f52705b4", "corpus_id": "9901844"}, "relationships": null}, {"id_": "graves2006-1", "type_": "citation", "bounding_boxes": [{"left": 0.38562091503267976, "top": 0.571969696969697, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "graves2006-1"}], "data": {"key": "graves2006", "bibitem_text": "A.~Graves, S.~Fern\\'a ndez, F.~Gomez, and J.~Schmidhuber. Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In \\em ICML , pages 369--376. ACM, 2006.", "paper_id": "96494e722f58705fa20302fe6179d483f52705b4", "corpus_id": "9901844"}, "relationships": null}, {"id_": "graves2006-2", "type_": "citation", "bounding_boxes": [{"left": 0.5179738562091504, "top": 0.7664141414141414, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 4, "tex_path": "N/A", "entity_id": "graves2006-2"}], "data": {"key": "graves2006", "bibitem_text": "A.~Graves, S.~Fern\\'a ndez, F.~Gomez, and J.~Schmidhuber. Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In \\em ICML , pages 369--376. ACM, 2006.", "paper_id": "96494e722f58705fa20302fe6179d483f52705b4", "corpus_id": "9901844"}, "relationships": null}, {"id_": "graves2014-0", "type_": "citation", "bounding_boxes": [{"left": 0.44281045751633985, "top": 0.4532828282828283, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "graves2014-0"}], "data": {"key": "graves2014", "bibitem_text": "A.~Graves and N.~Jaitly. Towards end-to-end speech recognition with recurrent neural networks. In \\em ICML , 2014.", "paper_id": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f", "corpus_id": "1166498"}, "relationships": null}, {"id_": "graves2014-1", "type_": "citation", "bounding_boxes": [{"left": 0.7271241830065359, "top": 0.5858585858585859, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "graves2014-1"}], "data": {"key": "graves2014", "bibitem_text": "A.~Graves and N.~Jaitly. Towards end-to-end speech recognition with recurrent neural networks. In \\em ICML , 2014.", "paper_id": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f", "corpus_id": "1166498"}, "relationships": null}, {"id_": "graves2013drnn-0", "type_": "citation", "bounding_boxes": [{"left": 0.20751633986928106, "top": 0.40404040404040403, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "graves2013drnn-0"}, {"left": 0.3888888888888889, "top": 0.41792929292929293, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "graves2013drnn-0"}], "data": {"key": "graves2013drnn", "bibitem_text": "A.~Graves, A.-r. Mohamed, and G.~Hinton. Speech recognition with deep recurrent neural networks. In \\em ICASSP , 2013.", "paper_id": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d", "corpus_id": "206741496"}, "relationships": null}, {"id_": "graves2013drnn-1", "type_": "citation", "bounding_boxes": [{"left": 0.673202614379085, "top": 0.3648989898989899, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 5, "tex_path": "N/A", "entity_id": "graves2013drnn-1"}], "data": {"key": "graves2013drnn", "bibitem_text": "A.~Graves, A.-r. Mohamed, and G.~Hinton. Speech recognition with deep recurrent neural networks. In \\em ICASSP , 2013.", "paper_id": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d", "corpus_id": "206741496"}, "relationships": null}, {"id_": "sak2014-0", "type_": "citation", "bounding_boxes": [{"left": 0.23366013071895425, "top": 0.40404040404040403, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "sak2014-0"}], "data": {"key": "sak2014", "bibitem_text": "H.~H.~Sak, A.~Senior, and F.~Beaufays. Long short-term memory recurrent neural network architectures for large scale acoustic modeling. In \\em Interspeech , 2014.", "paper_id": "067e07b725ab012c80aa2f87857f6791c1407f6d", "corpus_id": "6263878"}, "relationships": null}, {"id_": "hannun2014deepspeech-0", "type_": "citation", "bounding_boxes": [{"left": 0.29248366013071897, "top": 0.4696969696969697, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 0, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-0"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-1", "type_": "citation", "bounding_boxes": [{"left": 0.7728758169934641, "top": 0.648989898989899, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 0, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-1"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-2", "type_": "citation", "bounding_boxes": [{"left": 0.7875816993464052, "top": 0.773989898989899, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 0, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-2"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-3", "type_": "citation", "bounding_boxes": [{"left": 0.7124183006535948, "top": 0.36363636363636365, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 1, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-3"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-4", "type_": "citation", "bounding_boxes": [{"left": 0.3660130718954248, "top": 0.7323232323232324, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 1, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-4"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-5", "type_": "citation", "bounding_boxes": [{"left": 0.5735294117647058, "top": 0.4532828282828283, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-5"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-6", "type_": "citation", "bounding_boxes": [{"left": 0.7761437908496732, "top": 0.5858585858585859, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-6"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-7", "type_": "citation", "bounding_boxes": [{"left": 0.6666666666666666, "top": 0.7310606060606061, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-7"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-8", "type_": "citation", "bounding_boxes": [{"left": 0.5016339869281046, "top": 0.7803030303030303, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-8"}, {"left": 0.43300653594771243, "top": 0.8080808080808081, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-8"}, {"left": 0.3660130718954248, "top": 0.821969696969697, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-8"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-9", "type_": "citation", "bounding_boxes": [{"left": 0.23366013071895425, "top": 0.42297979797979796, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 3, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-9"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-10", "type_": "citation", "bounding_boxes": [{"left": 0.27124183006535946, "top": 0.8434343434343434, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 4, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-10"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-11", "type_": "citation", "bounding_boxes": [{"left": 0.2549019607843137, "top": 0.6553030303030303, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 8, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-11"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-12", "type_": "citation", "bounding_boxes": [{"left": 0.7990196078431373, "top": 0.6590909090909091, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 10, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-12"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-13", "type_": "citation", "bounding_boxes": [{"left": 0.35947712418300654, "top": 0.7904040404040404, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 10, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-13"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014deepspeech-14", "type_": "citation", "bounding_boxes": [{"left": 0.5065359477124183, "top": 0.4494949494949495, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 15, "tex_path": "N/A", "entity_id": "hannun2014deepspeech-14"}], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "hannun2014firstpass-0", "type_": "citation", "bounding_boxes": [{"left": 0.7516339869281046, "top": 0.5858585858585859, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "hannun2014firstpass-0"}], "data": {"key": "hannun2014firstpass", "bibitem_text": "A.~Y. Hannun, A.~L. Maas, D.~Jurafsky, and A.~Y. Ng. First-pass large vocabulary continuous speech recognition using bi-directional recurrent DNN s. abs/1408.2873, 2014. http://arxiv.org/abs/1408.2873.", "paper_id": "79d1e429c241d0aa47a2194246256a5bc79585bc", "corpus_id": "16783611"}, "relationships": null}, {"id_": "hannun2014firstpass-1", "type_": "citation", "bounding_boxes": [{"left": 0.5686274509803921, "top": 0.88510101010101, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 10, "tex_path": "N/A", "entity_id": "hannun2014firstpass-1"}], "data": {"key": "hannun2014firstpass", "bibitem_text": "A.~Y. Hannun, A.~L. Maas, D.~Jurafsky, and A.~Y. Ng. First-pass large vocabulary continuous speech recognition using bi-directional recurrent DNN s. abs/1408.2873, 2014. http://arxiv.org/abs/1408.2873.", "paper_id": "79d1e429c241d0aa47a2194246256a5bc79585bc", "corpus_id": "16783611"}, "relationships": null}, {"id_": "heafield2013kenlm-0", "type_": "citation", "bounding_boxes": [{"left": 0.4035947712418301, "top": 0.6868686868686869, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 10, "tex_path": "N/A", "entity_id": "heafield2013kenlm-0"}], "data": {"key": "heafield2013kenlm", "bibitem_text": "K.~Heafield, I.~Pouzyrevsky, J.~H. Clark, and P.~Koehn. Scalable modified Kneser-Ney language model estimation. In \\em Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics , Sofia, Bulgaria, 8 2013.", "paper_id": "774e560a2cadcb84f4b1def7b152e5398b062efb", "corpus_id": "2561041"}, "relationships": null}, {"id_": "hinton2012-0", "type_": "citation", "bounding_boxes": [{"left": 0.6993464052287581, "top": 0.36237373737373735, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "hinton2012-0"}], "data": {"key": "hinton2012", "bibitem_text": "G.~Hinton, L.~Deng, D.~Yu, G.~Dahl, A.~Mohamed, N.~Jaitly, A.~Senior, V.~Vanhoucke, P.~Nguyen, T.~Sainath, and B.~Kingsbury. Deep neural networks for acoustic modeling in speech recognition. \\em IEEE Signal Processing Magazine, 29(November):82--97, 2012.", "paper_id": "e33cbb25a8c7390aec6a398e36381f4f7770c283", "corpus_id": "7230302"}, "relationships": null}, {"id_": "hochreiter1997lstm-0", "type_": "citation", "bounding_boxes": [{"left": 0.2761437908496732, "top": 0.6123737373737373, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 4, "tex_path": "N/A", "entity_id": "hochreiter1997lstm-0"}], "data": {"key": "hochreiter1997lstm", "bibitem_text": "S.~Hochreiter and J.~Schmidhuber. Long short-term memory. \\em Neural Computation, 9(8):1735---1780, 1997.", "paper_id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9", "corpus_id": "1915014"}, "relationships": null}, {"id_": "hochreiter1997lstm-1", "type_": "citation", "bounding_boxes": [{"left": 0.45751633986928103, "top": 0.5656565656565656, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 7, "tex_path": "N/A", "entity_id": "hochreiter1997lstm-1"}], "data": {"key": "hochreiter1997lstm", "bibitem_text": "S.~Hochreiter and J.~Schmidhuber. Long short-term memory. \\em Neural Computation, 9(8):1735---1780, 1997.", "paper_id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9", "corpus_id": "1915014"}, "relationships": null}, {"id_": "jaitly2013-0", "type_": "citation", "bounding_boxes": [{"left": 0.477124183006536, "top": 0.8358585858585859, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "jaitly2013-0"}], "data": {"key": "jaitly2013", "bibitem_text": "N.~Jaitly and G.~Hinton. Vocal tract length perturbation (VTLP) improves speech recognition. In \\em ICML Workshop on Deep Learning for Audio, Speech, and Language Processing , 2013.", "paper_id": "f79174a79b0391b6c75035abe1ebc7f5d52445f6", "corpus_id": "14140670"}, "relationships": null}, {"id_": "jozefowicz2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.5980392156862745, "top": 0.6060606060606061, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 7, "tex_path": "N/A", "entity_id": "jozefowicz2015-0"}], "data": {"key": "jozefowicz2015", "bibitem_text": "R.~Jozefowicz, W.~Zaremba, and I.~Sutskever. An empirical exploration of recurrent network architectures. In \\em ICML , 2015.", "paper_id": "5b8364c21155d3d2cd38ea4c8b8580beba9a3250", "corpus_id": "9668607"}, "relationships": null}, {"id_": "kapralove2014-0", "type_": "citation", "bounding_boxes": [{"left": 0.37254901960784315, "top": 0.898989898989899, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "kapralove2014-0"}], "data": {"key": "kapralove2014", "bibitem_text": "O.~Kapralova, J.~Alex, E.~Weinstein, P.~Moreno, and O.~Siohan. A big data approach to acoustic model training corpus selection. In \\em Interspeech , 2014.", "paper_id": "dd8a3b42d0b0785a4f30e096c8c3959ba1520d3d", "corpus_id": "5917427"}, "relationships": null}, {"id_": "Knowlton:1965:FSA:365628.365655-0", "type_": "citation", "bounding_boxes": [{"left": 0.4934640522875817, "top": 0.8712121212121212, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 13, "tex_path": "N/A", "entity_id": "Knowlton:1965:FSA:365628.365655-0"}], "data": {"key": "Knowlton:1965:FSA:365628.365655", "bibitem_text": "K.~C. Knowlton. A fast storage allocator. \\em Commun. ACM, 8(10):623--624, Oct. 1965.", "paper_id": "8d7ab91362fa1319d696a0dc538ca881352bda76", "corpus_id": "9012033"}, "relationships": null}, {"id_": "ko2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.5016339869281046, "top": 0.8358585858585859, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "ko2015-0"}], "data": {"key": "ko2015", "bibitem_text": "T.~Ko, V.~Peddinti, D.~Povey, and S.~Khudanpur. Audio augmentation for speech recognition. In \\em Interspeech , 2015.", "paper_id": "66661a68dbf1d98d794fd025113b103683510303", "corpus_id": "7360763"}, "relationships": null}, {"id_": "krizhevsky2012imagenet-0", "type_": "citation", "bounding_boxes": [{"left": 0.7287581699346405, "top": 0.6767676767676768, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "krizhevsky2012imagenet-0"}, {"left": 0.2826797385620915, "top": 0.7032828282828283, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "krizhevsky2012imagenet-0"}], "data": {"key": "krizhevsky2012imagenet", "bibitem_text": "A.~Krizhevsky, I.~Sutskever, and G.~Hinton. Imagenet classification with deep convolutional neural networks. In \\em Advances in Neural Information Processing Systems 25 , pages 1106--1114, 2012.", "paper_id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "corpus_id": "195908774"}, "relationships": null}, {"id_": "laurent2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.6127450980392157, "top": 0.42803030303030304, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 5, "tex_path": "N/A", "entity_id": "laurent2015-0"}], "data": {"key": "laurent2015", "bibitem_text": "C.~Laurent, G.~Pereyra, P.~Brakel, Y.~Zhang, and Y.~Bengio. Batch normalized recurrent neural networks. abs/1510.01378, 2015. http://arxiv.org/abs/1510.01378.", "paper_id": "f95adc1d8daaa07a0c956826ec274ca9e2515ddc", "corpus_id": "516518"}, "relationships": null}, {"id_": "laurent2015-1", "type_": "citation", "bounding_boxes": [{"left": 0.6650326797385621, "top": 0.6603535353535354, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 5, "tex_path": "N/A", "entity_id": "laurent2015-1"}], "data": {"key": "laurent2015", "bibitem_text": "C.~Laurent, G.~Pereyra, P.~Brakel, Y.~Zhang, and Y.~Bengio. Batch normalized recurrent neural networks. abs/1510.01378, 2015. http://arxiv.org/abs/1510.01378.", "paper_id": "f95adc1d8daaa07a0c956826ec274ca9e2515ddc", "corpus_id": "516518"}, "relationships": null}, {"id_": "laurent2015-2", "type_": "citation", "bounding_boxes": [{"left": 0.46078431372549017, "top": 0.7992424242424242, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 5, "tex_path": "N/A", "entity_id": "laurent2015-2"}], "data": {"key": "laurent2015", "bibitem_text": "C.~Laurent, G.~Pereyra, P.~Brakel, Y.~Zhang, and Y.~Bengio. Batch normalized recurrent neural networks. abs/1510.01378, 2015. http://arxiv.org/abs/1510.01378.", "paper_id": "f95adc1d8daaa07a0c956826ec274ca9e2515ddc", "corpus_id": "516518"}, "relationships": null}, {"id_": "le2012faces-0", "type_": "citation", "bounding_boxes": [{"left": 0.7532679738562091, "top": 0.6767676767676768, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "le2012faces-0"}], "data": {"key": "le2012faces", "bibitem_text": "Q.~Le, M.~Ranzato, R.~Monga, M.~Devin, K.~Chen, G.~Corrado, J.~Dean, and A.~Ng. Building high-level features using large scale unsupervised learning. In \\em International Conference on Machine Learning , 2012.", "paper_id": "72e93aa6767ee683de7f001fa72f1314e40a8f35", "corpus_id": "206741597"}, "relationships": null}, {"id_": "lecun2004learningmethods-0", "type_": "citation", "bounding_boxes": [{"left": 0.6209150326797386, "top": 0.7941919191919192, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "lecun2004learningmethods-0"}], "data": {"key": "lecun2004learningmethods", "bibitem_text": "Y.~LeCun , F.~J. Huang, and L.~Bottou. Learning methods for generic object recognition with invariance to pose and lighting. In \\em Computer Vision and Pattern Recognition , volume~2, pages 97--104, 2004.", "paper_id": "f354310098e09c1e1dc88758fca36767fd9d084d", "corpus_id": "712708"}, "relationships": null}, {"id_": "maas2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.7973856209150327, "top": 0.5858585858585859, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "maas2015-0"}], "data": {"key": "maas2015", "bibitem_text": "A.~Maas, Z.~Xie, D.~Jurafsky, and A.~Ng. Lexicon-free conversational speech recognition with neural networks. In \\em NAACL , 2015.", "paper_id": "55ee875b9039febd378a3f8ac4e3d7603f83d57c", "corpus_id": "2111076"}, "relationships": null}, {"id_": "miao2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.7222222222222222, "top": 0.5997474747474747, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "miao2015-0"}], "data": {"key": "miao2015", "bibitem_text": "Y.~Miao, M.~Gowayyed, and F.~Metz. EESEN: End-to-end speech recognition using deep rnn models and wfst-based decoding. In \\em ASRU , 2015.", "paper_id": "97acdfb3d247f8250d865ef8a9169f06e40f138b", "corpus_id": "206514100"}, "relationships": null}, {"id_": "mohamed2011-0", "type_": "citation", "bounding_boxes": [{"left": 0.673202614379085, "top": 0.36237373737373735, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "mohamed2011-0"}], "data": {"key": "mohamed2011", "bibitem_text": "A.~Mohamed, G.~Dahl, and G.~Hinton. Acoustic modeling using deep belief networks. \\em IEEE Transactions on Audio, Speech, and Language Processing, (99), 2011.", "paper_id": "d2b62f77cb2864e465aa60bca6c26bb1d2f84963", "corpus_id": "9530137"}, "relationships": null}, {"id_": "jaitly2012-0", "type_": "citation", "bounding_boxes": [{"left": 0.7728758169934641, "top": 0.36237373737373735, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "jaitly2012-0"}], "data": {"key": "jaitly2012", "bibitem_text": "A.~S. N.~Jaitly, P.~Nguyen and V.~Vanhoucke. Application of pretrained deep neural networks to large vocabulary speech recognition. In \\em Interspeech , 2012.", "paper_id": "a4eb9f4fad5c5a1935c6d0532e2c765ee29b0b37", "corpus_id": "13521651"}, "relationships": null}, {"id_": "NervanaGPU-0", "type_": "citation", "bounding_boxes": [{"left": 0.3366013071895425, "top": 0.6313131313131313, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 21, "tex_path": "N/A", "entity_id": "NervanaGPU-0"}], "data": {"key": "NervanaGPU", "bibitem_text": ". Nervana GPU. https://github.com/NervanaSystems/nervanagpu. Accessed: 2015-11-06."}, "relationships": null}, {"id_": "niu2013-0", "type_": "citation", "bounding_boxes": [{"left": 0.40522875816993464, "top": 0.49747474747474746, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 11, "tex_path": "N/A", "entity_id": "niu2013-0"}], "data": {"key": "niu2013", "bibitem_text": "J.~Niu, L.~Xie, L.~Jia, and N.~Hu. Context-dependent deep neural networks for commercial mandarin speech recognition applications. In \\em APSIPA , 2013.", "paper_id": "63421fcff7a8c5bd45fffcff9613b49cade9b6e1", "corpus_id": "6811523"}, "relationships": null}, {"id_": "panayotov2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.7222222222222222, "top": 0.8712121212121212, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "panayotov2015-0"}], "data": {"key": "panayotov2015", "bibitem_text": "V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur. Librispeech: an asr corpus based on public domain audio books. In \\em ICASSP , 2015.", "paper_id": "34038d9424ce602d7ac917a4e582d977725d4393", "corpus_id": "2191379"}, "relationships": null}, {"id_": "panayotov2015-1", "type_": "citation", "bounding_boxes": [{"left": 0.7892156862745098, "top": 0.26136363636363635, "width": 0.014705882352941176, "height": 0.007575757575757576, "page": 14, "tex_path": "N/A", "entity_id": "panayotov2015-1"}], "data": {"key": "panayotov2015", "bibitem_text": "V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur. Librispeech: an asr corpus based on public domain audio books. In \\em ICASSP , 2015.", "paper_id": "34038d9424ce602d7ac917a4e582d977725d4393", "corpus_id": "2191379"}, "relationships": null}, {"id_": "panayotov2015-2", "type_": "citation", "bounding_boxes": [{"left": 0.4362745098039216, "top": 0.6982323232323232, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 17, "tex_path": "N/A", "entity_id": "panayotov2015-2"}], "data": {"key": "panayotov2015", "bibitem_text": "V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur. Librispeech: an asr corpus based on public domain audio books. In \\em ICASSP , 2015.", "paper_id": "34038d9424ce602d7ac917a4e582d977725d4393", "corpus_id": "2191379"}, "relationships": null}, {"id_": "pascanu2012-0", "type_": "citation", "bounding_boxes": [{"left": 0.4542483660130719, "top": 0.3207070707070707, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 16, "tex_path": "N/A", "entity_id": "pascanu2012-0"}], "data": {"key": "pascanu2012", "bibitem_text": "R.~Pascanu, T.~Mikolov, and Y.~Bengio. On the difficulty of training recurrent neural networks. abs/1211.5063, 2012. http://arxiv.org/abs/1211.5063.", "paper_id": "84069287da0a6b488b8c933f3cb5be759cb6237e", "corpus_id": "14650762"}, "relationships": null}, {"id_": "Patarasuk:2009:BOA:1482176.1482266-0", "type_": "citation", "bounding_boxes": [{"left": 0.3055555555555556, "top": 0.63510101010101, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 12, "tex_path": "N/A", "entity_id": "Patarasuk:2009:BOA:1482176.1482266-0"}], "data": {"key": "Patarasuk:2009:BOA:1482176.1482266", "bibitem_text": "P.~Patarasuk and X.~Yuan. Bandwidth optimal all-reduce algorithms for clusters of workstations. \\em J. Parallel Distrib. Comput., 69(2):117--124, Feb. 2009.", "paper_id": "6f4e48c2a5de9337d147ebbb7d0ff0e555adceca", "corpus_id": "7433454"}, "relationships": null}, {"id_": "raina2009large-0", "type_": "citation", "bounding_boxes": [{"left": 0.5849673202614379, "top": 0.6906565656565656, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "raina2009large-0"}], "data": {"key": "raina2009large", "bibitem_text": "R.~Raina, A.~Madhavan, and A.~Ng. Large-scale deep unsupervised learning using graphics processors. In \\em 26th International Conference on Machine Learning , 2009.", "paper_id": "e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1", "corpus_id": "392458"}, "relationships": null}, {"id_": "renals1994-0", "type_": "citation", "bounding_boxes": [{"left": 0.6683006535947712, "top": 0.32196969696969696, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "renals1994-0"}], "data": {"key": "renals1994", "bibitem_text": "S.~Renals, N.~Morgan, H.~Bourlard, M.~Cohen, and H.~Franco. Connectionist probability estimators in HMM speech recognition. \\em IEEE Transactions on Speech and Audio Processing, 2(1):161--174, 1994.", "paper_id": "a08c99425ad94eed67d059813511fe9ca55e73eb", "corpus_id": "2077908"}, "relationships": null}, {"id_": "robinson1996-0", "type_": "citation", "bounding_boxes": [{"left": 0.2173202614379085, "top": 0.34974747474747475, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "robinson1996-0"}], "data": {"key": "robinson1996", "bibitem_text": "T.~Robinson, M.~Hochberg, and S.~Renals. The use of recurrent neural networks in continuous speech recognition. pages 253--258, 1996.", "paper_id": "03bc854feaee144b54924b440eff02ed9082cc6b", "corpus_id": "8375725"}, "relationships": null}, {"id_": "sainath2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.7973856209150327, "top": 0.40404040404040403, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "sainath2015-0"}], "data": {"key": "sainath2015", "bibitem_text": "T.~Sainath, O.~Vinyals, A.~Senior, and H.~Sak. Convolutional, long short-term memory, fully connected deep neural networks. In \\em ICASSP , 2015.", "paper_id": "dec2ccce1ecb34bab02c42c2dd18cb468470adf8", "corpus_id": "898670"}, "relationships": null}, {"id_": "sainath2015-1", "type_": "citation", "bounding_boxes": [{"left": 0.28431372549019607, "top": 0.7184343434343434, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 6, "tex_path": "N/A", "entity_id": "sainath2015-1"}], "data": {"key": "sainath2015", "bibitem_text": "T.~Sainath, O.~Vinyals, A.~Senior, and H.~Sak. Convolutional, long short-term memory, fully connected deep neural networks. In \\em ICASSP , 2015.", "paper_id": "dec2ccce1ecb34bab02c42c2dd18cb468470adf8", "corpus_id": "898670"}, "relationships": null}, {"id_": "sainath2015-2", "type_": "citation", "bounding_boxes": [{"left": 0.4084967320261438, "top": 0.5517676767676768, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 7, "tex_path": "N/A", "entity_id": "sainath2015-2"}], "data": {"key": "sainath2015", "bibitem_text": "T.~Sainath, O.~Vinyals, A.~Senior, and H.~Sak. Convolutional, long short-term memory, fully connected deep neural networks. In \\em ICASSP , 2015.", "paper_id": "dec2ccce1ecb34bab02c42c2dd18cb468470adf8", "corpus_id": "898670"}, "relationships": null}, {"id_": "sainath2013cnn-0", "type_": "citation", "bounding_boxes": [{"left": 0.7222222222222222, "top": 0.37626262626262624, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "sainath2013cnn-0"}], "data": {"key": "sainath2013cnn", "bibitem_text": "T.~N. Sainath, A.~rahman Mohamed, B.~Kingsbury, and B.~Ramabhadran. Deep convolutional neural networks for LVCSR . In \\em ICASSP , 2013.", "paper_id": "57a5fa22f10ce6ccf27286f74a050d2dac037e06", "corpus_id": "13816461"}, "relationships": null}, {"id_": "sainath2013cnn-1", "type_": "citation", "bounding_boxes": [{"left": 0.6013071895424836, "top": 0.6906565656565656, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 8, "tex_path": "N/A", "entity_id": "sainath2013cnn-1"}], "data": {"key": "sainath2013cnn", "bibitem_text": "T.~N. Sainath, A.~rahman Mohamed, B.~Kingsbury, and B.~Ramabhadran. Deep convolutional neural networks for LVCSR . In \\em ICASSP , 2013.", "paper_id": "57a5fa22f10ce6ccf27286f74a050d2dac037e06", "corpus_id": "13816461"}, "relationships": null}, {"id_": "sak2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.7467320261437909, "top": 0.5997474747474747, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "sak2015-0"}], "data": {"key": "sak2015", "bibitem_text": "H.~Sak, A.~Senior, K.~Rao, and F.~Beaufays. Fast and accurate recurrent neural network acoustic models for speech recognition. abs/1507.06947, 2015. http://arxiv.org/abs/1507.06947.", "paper_id": "9fca2af9a0e3f2c5c3ed47abb3ebd21b7265ac2b", "corpus_id": "11298362"}, "relationships": null}, {"id_": "sak2015-1", "type_": "citation", "bounding_boxes": [{"left": 0.23202614379084968, "top": 0.6414141414141414, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "sak2015-1"}], "data": {"key": "sak2015", "bibitem_text": "H.~Sak, A.~Senior, K.~Rao, and F.~Beaufays. Fast and accurate recurrent neural network acoustic models for speech recognition. abs/1507.06947, 2015. http://arxiv.org/abs/1507.06947.", "paper_id": "9fca2af9a0e3f2c5c3ed47abb3ebd21b7265ac2b", "corpus_id": "11298362"}, "relationships": null}, {"id_": "sak2015-2", "type_": "citation", "bounding_boxes": [{"left": 0.5833333333333334, "top": 0.10732323232323232, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 15, "tex_path": "N/A", "entity_id": "sak2015-2"}], "data": {"key": "sak2015", "bibitem_text": "H.~Sak, A.~Senior, K.~Rao, and F.~Beaufays. Fast and accurate recurrent neural network acoustic models for speech recognition. abs/1507.06947, 2015. http://arxiv.org/abs/1507.06947.", "paper_id": "9fca2af9a0e3f2c5c3ed47abb3ebd21b7265ac2b", "corpus_id": "11298362"}, "relationships": null}, {"id_": "sak2014b-0", "type_": "citation", "bounding_boxes": [{"left": 0.2581699346405229, "top": 0.40404040404040403, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "sak2014b-0"}], "data": {"key": "sak2014b", "bibitem_text": "H.~Sak, O.~Vinyals, G.~Heigold, A.~Senior, E.~McDermott, R.~Monga, and M.~Mao. Sequence discriminative distributed training of long shortterm memory recurrent neural networks. In \\em Interspeech , 2014.", "paper_id": "965c9aec5e68d49142c5af6a9f0a984f6c2c743a", "corpus_id": "28800623"}, "relationships": null}, {"id_": "sapp2008synth-0", "type_": "citation", "bounding_boxes": [{"left": 0.6454248366013072, "top": 0.7941919191919192, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "sapp2008synth-0"}], "data": {"key": "sapp2008synth", "bibitem_text": "B.~Sapp, A.~Saxena, and A.~Ng. A fast data collection and augmentation procedure for object recognition. In \\em AAAI Twenty-Third Conference on Artificial Intelligence , 2008.", "paper_id": "1f3a2cdbd1a27485bb76dd666f6fd3baf5bb1ab5", "corpus_id": "1817910"}, "relationships": null}, {"id_": "schuster1997bidirectional-0", "type_": "citation", "bounding_boxes": [{"left": 0.7107843137254902, "top": 0.851010101010101, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 3, "tex_path": "N/A", "entity_id": "schuster1997bidirectional-0"}], "data": {"key": "schuster1997bidirectional", "bibitem_text": "M.~Schuster and K.~K. Paliwal. Bidirectional recurrent neural networks. \\em IEEE Transactions on Signal Processing, 45(11):2673--2681, 1997.", "paper_id": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85", "corpus_id": "18375389"}, "relationships": null}, {"id_": "seide2011b-0", "type_": "citation", "bounding_boxes": [{"left": 0.7973856209150327, "top": 0.36237373737373735, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "seide2011b-0"}], "data": {"key": "seide2011b", "bibitem_text": "F.~Seide, G.~Li, and D.~Yu. Conversational speech transcription using context-dependent deep neural networks. In \\em Interspeech , pages 437--440, 2011.", "paper_id": "473f0739666af2791ad6592822118240ed968b70", "corpus_id": "398770"}, "relationships": null}, {"id_": "shan2010-0", "type_": "citation", "bounding_boxes": [{"left": 0.380718954248366, "top": 0.49747474747474746, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 11, "tex_path": "N/A", "entity_id": "shan2010-0"}, {"left": 0.25326797385620914, "top": 0.4696969696969697, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 11, "tex_path": "N/A", "entity_id": "shan2010-0"}], "data": {"key": "shan2010", "bibitem_text": "J.~Shan, G.~Wu, Z.~Hu, X.~Tang, M.~Jansche, and P.~Moreno. Search by voice in mandarin chinese. In \\em Interspeech , 2010.", "paper_id": "fc7ac43bf47c585f1486beb66be6a2c28d5e9197", "corpus_id": "1227267"}, "relationships": null}, {"id_": "soltau2014-0", "type_": "citation", "bounding_boxes": [{"left": 0.6258169934640523, "top": 0.6906565656565656, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 8, "tex_path": "N/A", "entity_id": "soltau2014-0"}], "data": {"key": "soltau2014", "bibitem_text": "H.~Soltau, G.~Saon, and T.~Sainath. Joint training of convolutional and non-convolutional neural networks. In \\em ICASSP , 2014.", "paper_id": "705f3d987760d8aee5db1431987007d4b304d96d", "corpus_id": "14212185"}, "relationships": null}, {"id_": "sutskever2013nag-0", "type_": "citation", "bounding_boxes": [{"left": 0.26143790849673204, "top": 0.30808080808080807, "width": 0.013071895424836602, "height": 0.008838383838383838, "page": 16, "tex_path": "N/A", "entity_id": "sutskever2013nag-0"}], "data": {"key": "sutskever2013nag", "bibitem_text": "I.~Sutskever, J.~Martens, G.~Dahl, and G.~Hinton. On the importance of momentum and initialization in deep learning. In \\em 30th International Conference on Machine Learning , 2013.", "paper_id": "aa7bfd2304201afbb19971ebde87b17e40242e91", "corpus_id": "10940950"}, "relationships": null}, {"id_": "sutskever2014seq-0", "type_": "citation", "bounding_boxes": [{"left": 0.7238562091503268, "top": 0.494949494949495, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "sutskever2014seq-0"}], "data": {"key": "sutskever2014seq", "bibitem_text": "I.~Sutskever, O.~Vinyals, and Q.~V. Le. Sequence to sequence learning with neural networks. 2014. http://arxiv.org/abs/1409.3215.", "paper_id": "cea967b59209c6be22829699f05b8b1ac4dc092d", "corpus_id": "7961699"}, "relationships": null}, {"id_": "sutskever2014seq-1", "type_": "citation", "bounding_boxes": [{"left": 0.4477124183006536, "top": 0.5517676767676768, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 7, "tex_path": "N/A", "entity_id": "sutskever2014seq-1"}], "data": {"key": "sutskever2014seq", "bibitem_text": "I.~Sutskever, O.~Vinyals, and Q.~V. Le. Sequence to sequence learning with neural networks. 2014. http://arxiv.org/abs/1409.3215.", "paper_id": "cea967b59209c6be22829699f05b8b1ac4dc092d", "corpus_id": "7961699"}, "relationships": null}, {"id_": "ioffe2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.4918300653594771, "top": 0.34974747474747475, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 1, "tex_path": "N/A", "entity_id": "ioffe2015-0"}], "data": {"key": "ioffe2015", "bibitem_text": "C.~Szegedy and S.~Ioffe. Batch normalization: Accelerating deep network training by reducing internal covariate shift. abs/1502.03167, 2015. http://arxiv.org/abs/1502.03167.", "paper_id": "4d376d6978dad0374edfa6709c9556b42d3594d3", "corpus_id": "5808102"}, "relationships": null}, {"id_": "ioffe2015-1", "type_": "citation", "bounding_boxes": [{"left": 0.7320261437908496, "top": 0.3787878787878788, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 5, "tex_path": "N/A", "entity_id": "ioffe2015-1"}], "data": {"key": "ioffe2015", "bibitem_text": "C.~Szegedy and S.~Ioffe. Batch normalization: Accelerating deep network training by reducing internal covariate shift. abs/1502.03167, 2015. http://arxiv.org/abs/1502.03167.", "paper_id": "4d376d6978dad0374edfa6709c9556b42d3594d3", "corpus_id": "5808102"}, "relationships": null}, {"id_": "ioffe2015-2", "type_": "citation", "bounding_boxes": [{"left": 0.5898692810457516, "top": 0.6174242424242424, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 6, "tex_path": "N/A", "entity_id": "ioffe2015-2"}], "data": {"key": "ioffe2015", "bibitem_text": "C.~Szegedy and S.~Ioffe. Batch normalization: Accelerating deep network training by reducing internal covariate shift. abs/1502.03167, 2015. http://arxiv.org/abs/1502.03167.", "paper_id": "4d376d6978dad0374edfa6709c9556b42d3594d3", "corpus_id": "5808102"}, "relationships": null}, {"id_": "szegedy2014googlenet-0", "type_": "citation", "bounding_boxes": [{"left": 0.6388888888888888, "top": 0.7310606060606061, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "szegedy2014googlenet-0"}], "data": {"key": "szegedy2014googlenet", "bibitem_text": "C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan, V.~Vanhoucke, and A.~Rabinovich. Going deeper with convolutions. 2014."}, "relationships": null}, {"id_": "Thakur05optimizationof-0", "type_": "citation", "bounding_boxes": [{"left": 0.3300653594771242, "top": 0.63510101010101, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 12, "tex_path": "N/A", "entity_id": "Thakur05optimizationof-0"}], "data": {"key": "Thakur05optimizationof", "bibitem_text": "R.~Thakur and R.~Rabenseifner. Optimization of collective communication operations in mpich. \\em International Journal of High Performance Computing Applications, 19:49--66, 2005.", "paper_id": "b471f0b45d69c3fd3333f0322bab64b2a4ae9369", "corpus_id": "90404"}, "relationships": null}, {"id_": "vesely2013-0", "type_": "citation", "bounding_boxes": [{"left": 0.6356209150326797, "top": 0.5782828282828283, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 8, "tex_path": "N/A", "entity_id": "vesely2013-0"}], "data": {"key": "vesely2013", "bibitem_text": "K.~Vesely, A.~Ghoshal, L.~Burget, and D.~Povey. Sequence-discriminative training of deep neural networks. In \\em Interspeech , 2013.", "paper_id": "b48168acba4a6ca33ad0f11bbf1c7d8106333822", "corpus_id": "2827512"}, "relationships": null}, {"id_": "waibel1989-0", "type_": "citation", "bounding_boxes": [{"left": 0.2434640522875817, "top": 0.34974747474747475, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 2, "tex_path": "N/A", "entity_id": "waibel1989-0"}], "data": {"key": "waibel1989", "bibitem_text": "A.~Waibel, T.~Hanazawa, G.~Hinton, K.~Shikano, and K.~Lang. Phoneme recognition using time-delay neural networks,\u201d acoustics speech and signal processing. \\em{IEEE} Transactions on Acoustics, Speech and Signal Processing, 37(3):328--339, 1989.", "paper_id": "cd62c9976534a6a2096a38244f6cbb03635a127e", "corpus_id": "9563026"}, "relationships": null}, {"id_": "waibel1989-1", "type_": "citation", "bounding_boxes": [{"left": 0.5098039215686274, "top": 0.5643939393939394, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 8, "tex_path": "N/A", "entity_id": "waibel1989-1"}], "data": {"key": "waibel1989", "bibitem_text": "A.~Waibel, T.~Hanazawa, G.~Hinton, K.~Shikano, and K.~Lang. Phoneme recognition using time-delay neural networks,\u201d acoustics speech and signal processing. \\em{IEEE} Transactions on Acoustics, Speech and Signal Processing, 37(3):328--339, 1989.", "paper_id": "cd62c9976534a6a2096a38244f6cbb03635a127e", "corpus_id": "9563026"}, "relationships": null}, {"id_": "williams1990-0", "type_": "citation", "bounding_boxes": [{"left": 0.4542483660130719, "top": 0.7045454545454546, "width": 0.014705882352941176, "height": 0.008838383838383838, "page": 6, "tex_path": "N/A", "entity_id": "williams1990-0"}], "data": {"key": "williams1990", "bibitem_text": "R.~Williams and J.~Peng. An efficient gradient-based algorithm for online training of recurrent network trajectories. \\em Neural computation, 2:490--501, 1990.", "paper_id": "26bc0449360d7016f684eafae5b5d2feded32041", "corpus_id": "12979634"}, "relationships": null}, {"id_": "yoshioka2015-0", "type_": "citation", "bounding_boxes": [{"left": 0.7696078431372549, "top": 0.7563131313131313, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 18, "tex_path": "N/A", "entity_id": "yoshioka2015-0"}], "data": {"key": "yoshioka2015", "bibitem_text": "T.~Yoshioka, N.~Ito, M.~Delcroix, A.~Ogawa, K.~Kinoshita, M.~F.~C. Yu, W.~J. Fabian, M.~Espi, T.~Higuchi, S.~Araki, and T.~Nakatani. The ntt chime-3 system: Advances in speech enhancement and recognition for mobile multi-microphone devices. In \\em IEEE ASRU , 2015.", "paper_id": "0c73d7be1236683d18a54751e783d6cce36bfc35", "corpus_id": "31913713"}, "relationships": null}, {"id_": "zaremba2014-0", "type_": "citation", "bounding_boxes": [{"left": 0.17647058823529413, "top": 0.7449494949494949, "width": 0.016339869281045753, "height": 0.008838383838383838, "page": 6, "tex_path": "N/A", "entity_id": "zaremba2014-0"}], "data": {"key": "zaremba2014", "bibitem_text": "W.~Zaremba and I.~Sutskever. Learning to execute. abs/1410.4615, 2014. http://arxiv.org/abs/1410.4615.", "paper_id": "0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a", "corpus_id": "12730022"}, "relationships": null}, {"id_": "waibel1989", "type_": "citation", "bounding_boxes": [], "data": {"key": "waibel1989", "bibitem_text": "A.~Waibel, T.~Hanazawa, G.~Hinton, K.~Shikano, and K.~Lang. Phoneme recognition using time-delay neural networks,\u201d acoustics speech and signal processing. \\em{IEEE} Transactions on Acoustics, Speech and Signal Processing, 37(3):328--339, 1989.", "paper_id": "cd62c9976534a6a2096a38244f6cbb03635a127e", "corpus_id": "9563026"}, "relationships": null}, {"id_": "hochreiter1997lstm", "type_": "citation", "bounding_boxes": [], "data": {"key": "hochreiter1997lstm", "bibitem_text": "S.~Hochreiter and J.~Schmidhuber. Long short-term memory. \\em Neural Computation, 9(8):1735---1780, 1997.", "paper_id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9", "corpus_id": "1915014"}, "relationships": null}, {"id_": "hinton2012", "type_": "citation", "bounding_boxes": [], "data": {"key": "hinton2012", "bibitem_text": "G.~Hinton, L.~Deng, D.~Yu, G.~Dahl, A.~Mohamed, N.~Jaitly, A.~Senior, V.~Vanhoucke, P.~Nguyen, T.~Sainath, and B.~Kingsbury. Deep neural networks for acoustic modeling in speech recognition. \\em IEEE Signal Processing Magazine, 29(November):82--97, 2012.", "paper_id": "e33cbb25a8c7390aec6a398e36381f4f7770c283", "corpus_id": "7230302"}, "relationships": null}, {"id_": "raina2009large", "type_": "citation", "bounding_boxes": [], "data": {"key": "raina2009large", "bibitem_text": "R.~Raina, A.~Madhavan, and A.~Ng. Large-scale deep unsupervised learning using graphics processors. In \\em 26th International Conference on Machine Learning , 2009.", "paper_id": "e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1", "corpus_id": "392458"}, "relationships": null}, {"id_": "ellis1999", "type_": "citation", "bounding_boxes": [], "data": {"key": "ellis1999", "bibitem_text": "D.~Ellis and N.~Morgan. Size matters: An empirical study of neural network training for large vocabulary continuous speech recognition. In \\em ICASSP , volume~2, pages 1013--1016. IEEE, 1999.", "paper_id": "acf4e90062ca28e12f9e3a8c8b117030469d3e4b", "corpus_id": "1196476"}, "relationships": null}, {"id_": "laurent2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "laurent2015", "bibitem_text": "C.~Laurent, G.~Pereyra, P.~Brakel, Y.~Zhang, and Y.~Bengio. Batch normalized recurrent neural networks. abs/1510.01378, 2015. http://arxiv.org/abs/1510.01378.", "paper_id": "f95adc1d8daaa07a0c956826ec274ca9e2515ddc", "corpus_id": "516518"}, "relationships": null}, {"id_": "lecun2004learningmethods", "type_": "citation", "bounding_boxes": [], "data": {"key": "lecun2004learningmethods", "bibitem_text": "Y.~LeCun , F.~J. Huang, and L.~Bottou. Learning methods for generic object recognition with invariance to pose and lighting. In \\em Computer Vision and Pattern Recognition , volume~2, pages 97--104, 2004.", "paper_id": "f354310098e09c1e1dc88758fca36767fd9d084d", "corpus_id": "712708"}, "relationships": null}, {"id_": "shan2010", "type_": "citation", "bounding_boxes": [], "data": {"key": "shan2010", "bibitem_text": "J.~Shan, G.~Wu, Z.~Hu, X.~Tang, M.~Jansche, and P.~Moreno. Search by voice in mandarin chinese. In \\em Interspeech , 2010.", "paper_id": "fc7ac43bf47c585f1486beb66be6a2c28d5e9197", "corpus_id": "1227267"}, "relationships": null}, {"id_": "williams1990", "type_": "citation", "bounding_boxes": [], "data": {"key": "williams1990", "bibitem_text": "R.~Williams and J.~Peng. An efficient gradient-based algorithm for online training of recurrent network trajectories. \\em Neural computation, 2:490--501, 1990.", "paper_id": "26bc0449360d7016f684eafae5b5d2feded32041", "corpus_id": "12979634"}, "relationships": null}, {"id_": "jaitly2012", "type_": "citation", "bounding_boxes": [], "data": {"key": "jaitly2012", "bibitem_text": "A.~S. N.~Jaitly, P.~Nguyen and V.~Vanhoucke. Application of pretrained deep neural networks to large vocabulary speech recognition. In \\em Interspeech , 2012.", "paper_id": "a4eb9f4fad5c5a1935c6d0532e2c765ee29b0b37", "corpus_id": "13521651"}, "relationships": null}, {"id_": "zaremba2014", "type_": "citation", "bounding_boxes": [], "data": {"key": "zaremba2014", "bibitem_text": "W.~Zaremba and I.~Sutskever. Learning to execute. abs/1410.4615, 2014. http://arxiv.org/abs/1410.4615.", "paper_id": "0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a", "corpus_id": "12730022"}, "relationships": null}, {"id_": "jozefowicz2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "jozefowicz2015", "bibitem_text": "R.~Jozefowicz, W.~Zaremba, and I.~Sutskever. An empirical exploration of recurrent network architectures. In \\em ICML , 2015.", "paper_id": "5b8364c21155d3d2cd38ea4c8b8580beba9a3250", "corpus_id": "9668607"}, "relationships": null}, {"id_": "le2012faces", "type_": "citation", "bounding_boxes": [], "data": {"key": "le2012faces", "bibitem_text": "Q.~Le, M.~Ranzato, R.~Monga, M.~Devin, K.~Chen, G.~Corrado, J.~Dean, and A.~Ng. Building high-level features using large scale unsupervised learning. In \\em International Conference on Machine Learning , 2012.", "paper_id": "72e93aa6767ee683de7f001fa72f1314e40a8f35", "corpus_id": "206741597"}, "relationships": null}, {"id_": "maas2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "maas2015", "bibitem_text": "A.~Maas, Z.~Xie, D.~Jurafsky, and A.~Ng. Lexicon-free conversational speech recognition with neural networks. In \\em NAACL , 2015.", "paper_id": "55ee875b9039febd378a3f8ac4e3d7603f83d57c", "corpus_id": "2111076"}, "relationships": null}, {"id_": "NervanaGPU", "type_": "citation", "bounding_boxes": [], "data": {"key": "NervanaGPU", "bibitem_text": ". Nervana GPU. https://github.com/NervanaSystems/nervanagpu. Accessed: 2015-11-06."}, "relationships": null}, {"id_": "chan2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "chan2015", "bibitem_text": "W.~Chan, N.~Jaitly, Q.~Le, and O.~Vinyals. Listen, attend, and spell. abs/1508.01211, 2015. http://arxiv.org/abs/1508.01211.", "paper_id": "dc555e8156c956f823587ebbff018863e6d2a95e", "corpus_id": "14177763"}, "relationships": null}, {"id_": "barker2015chime", "type_": "citation", "bounding_boxes": [], "data": {"key": "barker2015chime", "bibitem_text": "J.~Barker, E.~Marxer, Ricard~Vincent, and S.~Watanabe. The third 'CHiME' speech separation and recognition challenge: Dataset, task and baselines. 2015. Submitted to IEEE 2015 Automatic Speech Recognition and Understanding Workshop (ASRU).", "paper_id": "eadf5023c90a6af8a0f8e8605bd8050cc13c23a3", "corpus_id": "4397499"}, "relationships": null}, {"id_": "bahdanau2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "bahdanau2015", "bibitem_text": "D.~Bahdanau, K.~Cho, and Y.~Bengio. Neural machine translation by jointly learning to align and translate. In \\em ICLR , 2015.", "paper_id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "corpus_id": "11212020"}, "relationships": null}, {"id_": "chorowski2015firstresults", "type_": "citation", "bounding_boxes": [], "data": {"key": "chorowski2015firstresults", "bibitem_text": "J.~Chorowski, D.~Bahdanau, K.~Cho, and Y.~Bengio. End-to-end continuous speech recognition using attention-based recurrent nn: First results. abs/1412.1602, 2015. http://arxiv.org/abs/1412.1602.", "paper_id": "47d2dc34e1d02a8109f5c04bb6939725de23716d", "corpus_id": "453615"}, "relationships": null}, {"id_": "cho2014", "type_": "citation", "bounding_boxes": [], "data": {"key": "cho2014", "bibitem_text": "K.~Cho, B.~Van~Merrienboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares, H.~Schwenk, and Y.~Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In \\em EMNLP , 2014.", "paper_id": "0b544dfe355a5070b60986319a3f51fb45d1348e", "corpus_id": "5590763"}, "relationships": null}, {"id_": "bourlard93", "type_": "citation", "bounding_boxes": [], "data": {"key": "bourlard93", "bibitem_text": "H.~Bourlard and N.~Morgan. \\em Connectionist Speech Recognition: A Hybrid Approach. Kluwer Academic Publishers, Norwell, MA, 1993.", "paper_id": "3d82e058a5c40954b8f5db170a298a889a254c37", "corpus_id": "61058350"}, "relationships": null}, {"id_": "sutskever2013nag", "type_": "citation", "bounding_boxes": [], "data": {"key": "sutskever2013nag", "bibitem_text": "I.~Sutskever, J.~Martens, G.~Dahl, and G.~Hinton. On the importance of momentum and initialization in deep learning. In \\em 30th International Conference on Machine Learning , 2013.", "paper_id": "aa7bfd2304201afbb19971ebde87b17e40242e91", "corpus_id": "10940950"}, "relationships": null}, {"id_": "chetlur14", "type_": "citation", "bounding_boxes": [], "data": {"key": "chetlur14", "bibitem_text": "S.~Chetlur, C.~Woolley, P.~Vandermersch, J.~Cohen, J.~Tran, B.~Catanzaro, and E.~Shelhamer. cuDNN: Efficient primitives for deep learning.", "paper_id": "31c36d445367ba204244bb74893c5654e31c3869", "corpus_id": "12330432"}, "relationships": null}, {"id_": "krizhevsky2012imagenet", "type_": "citation", "bounding_boxes": [], "data": {"key": "krizhevsky2012imagenet", "bibitem_text": "A.~Krizhevsky, I.~Sutskever, and G.~Hinton. Imagenet classification with deep convolutional neural networks. In \\em Advances in Neural Information Processing Systems 25 , pages 1106--1114, 2012.", "paper_id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "corpus_id": "195908774"}, "relationships": null}, {"id_": "Elsen2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "Elsen2015", "bibitem_text": "E.~Elsen. Optimizing RNN performance. http://svail.github.io/rnn_perf. Accessed: 2015-11-24."}, "relationships": null}, {"id_": "sutskever2014seq", "type_": "citation", "bounding_boxes": [], "data": {"key": "sutskever2014seq", "bibitem_text": "I.~Sutskever, O.~Vinyals, and Q.~V. Le. Sequence to sequence learning with neural networks. 2014. http://arxiv.org/abs/1409.3215.", "paper_id": "cea967b59209c6be22829699f05b8b1ac4dc092d", "corpus_id": "7961699"}, "relationships": null}, {"id_": "Thakur05optimizationof", "type_": "citation", "bounding_boxes": [], "data": {"key": "Thakur05optimizationof", "bibitem_text": "R.~Thakur and R.~Rabenseifner. Optimization of collective communication operations in mpich. \\em International Journal of High Performance Computing Applications, 19:49--66, 2005.", "paper_id": "b471f0b45d69c3fd3333f0322bab64b2a4ae9369", "corpus_id": "90404"}, "relationships": null}, {"id_": "bahdanau2015b", "type_": "citation", "bounding_boxes": [], "data": {"key": "bahdanau2015b", "bibitem_text": "D.~Bahdanau, J.~Chorowski, D.~Serdyuk, P.~Brakel, and Y.~Bengio. End-to-end attention-based large vocabulary speech recognition. abs/1508.04395, 2015. http://arxiv.org/abs/1508.04395.", "paper_id": "878ba5458e9e51f0b341fd9117fa0b43ef4096d3", "corpus_id": "11760007"}, "relationships": null}, {"id_": "szegedy2014googlenet", "type_": "citation", "bounding_boxes": [], "data": {"key": "szegedy2014googlenet", "bibitem_text": "C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan, V.~Vanhoucke, and A.~Rabinovich. Going deeper with convolutions. 2014."}, "relationships": null}, {"id_": "niu2013", "type_": "citation", "bounding_boxes": [], "data": {"key": "niu2013", "bibitem_text": "J.~Niu, L.~Xie, L.~Jia, and N.~Hu. Context-dependent deep neural networks for commercial mandarin speech recognition applications. In \\em APSIPA , 2013.", "paper_id": "63421fcff7a8c5bd45fffcff9613b49cade9b6e1", "corpus_id": "6811523"}, "relationships": null}, {"id_": "Patarasuk:2009:BOA:1482176.1482266", "type_": "citation", "bounding_boxes": [], "data": {"key": "Patarasuk:2009:BOA:1482176.1482266", "bibitem_text": "P.~Patarasuk and X.~Yuan. Bandwidth optimal all-reduce algorithms for clusters of workstations. \\em J. Parallel Distrib. Comput., 69(2):117--124, Feb. 2009.", "paper_id": "6f4e48c2a5de9337d147ebbb7d0ff0e555adceca", "corpus_id": "7433454"}, "relationships": null}, {"id_": "panayotov2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "panayotov2015", "bibitem_text": "V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur. Librispeech: an asr corpus based on public domain audio books. In \\em ICASSP , 2015.", "paper_id": "34038d9424ce602d7ac917a4e582d977725d4393", "corpus_id": "2191379"}, "relationships": null}, {"id_": "graves2013drnn", "type_": "citation", "bounding_boxes": [], "data": {"key": "graves2013drnn", "bibitem_text": "A.~Graves, A.-r. Mohamed, and G.~Hinton. Speech recognition with deep recurrent neural networks. In \\em ICASSP , 2013.", "paper_id": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d", "corpus_id": "206741496"}, "relationships": null}, {"id_": "sak2014", "type_": "citation", "bounding_boxes": [], "data": {"key": "sak2014", "bibitem_text": "H.~H.~Sak, A.~Senior, and F.~Beaufays. Long short-term memory recurrent neural network architectures for large scale acoustic modeling. In \\em Interspeech , 2014.", "paper_id": "067e07b725ab012c80aa2f87857f6791c1407f6d", "corpus_id": "6263878"}, "relationships": null}, {"id_": "jaitly2013", "type_": "citation", "bounding_boxes": [], "data": {"key": "jaitly2013", "bibitem_text": "N.~Jaitly and G.~Hinton. Vocal tract length perturbation (VTLP) improves speech recognition. In \\em ICML Workshop on Deep Learning for Audio, Speech, and Language Processing , 2013.", "paper_id": "f79174a79b0391b6c75035abe1ebc7f5d52445f6", "corpus_id": "14140670"}, "relationships": null}, {"id_": "Knowlton:1965:FSA:365628.365655", "type_": "citation", "bounding_boxes": [], "data": {"key": "Knowlton:1965:FSA:365628.365655", "bibitem_text": "K.~C. Knowlton. A fast storage allocator. \\em Commun. ACM, 8(10):623--624, Oct. 1965.", "paper_id": "8d7ab91362fa1319d696a0dc538ca881352bda76", "corpus_id": "9012033"}, "relationships": null}, {"id_": "coates2011icdar", "type_": "citation", "bounding_boxes": [], "data": {"key": "coates2011icdar", "bibitem_text": "A.~Coates, B.~Carpenter, C.~Case, S.~Satheesh, B.~Suresh, T.~Wang, D.~J. Wu, and A.~Y. Ng. Text detection and character recognition in scene images with unsupervised feature learning. In \\em International Conference on Document Analysis and Recognition , 2011.", "paper_id": "12244deb997152492d96c6246ec21b2b9804800d", "corpus_id": "16657844"}, "relationships": null}, {"id_": "miao2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "miao2015", "bibitem_text": "Y.~Miao, M.~Gowayyed, and F.~Metz. EESEN: End-to-end speech recognition using deep rnn models and wfst-based decoding. In \\em ASRU , 2015.", "paper_id": "97acdfb3d247f8250d865ef8a9169f06e40f138b", "corpus_id": "206514100"}, "relationships": null}, {"id_": "cieri2004Fisher", "type_": "citation", "bounding_boxes": [], "data": {"key": "cieri2004Fisher", "bibitem_text": "C.~Cieri, D.~Miller, and K.~Walker. The Fisher corpus: a resource for the next generations of speech-to-text. In \\em LREC , volume~4, pages 69--71, 2004.", "paper_id": "74ec753c27a01e93380c148ba886f8e0317c61ee", "corpus_id": "8414900"}, "relationships": null}, {"id_": "soltau2014", "type_": "citation", "bounding_boxes": [], "data": {"key": "soltau2014", "bibitem_text": "H.~Soltau, G.~Saon, and T.~Sainath. Joint training of convolutional and non-convolutional neural networks. In \\em ICASSP , 2014.", "paper_id": "705f3d987760d8aee5db1431987007d4b304d96d", "corpus_id": "14212185"}, "relationships": null}, {"id_": "renals1994", "type_": "citation", "bounding_boxes": [], "data": {"key": "renals1994", "bibitem_text": "S.~Renals, N.~Morgan, H.~Bourlard, M.~Cohen, and H.~Franco. Connectionist probability estimators in HMM speech recognition. \\em IEEE Transactions on Speech and Audio Processing, 2(1):161--174, 1994.", "paper_id": "a08c99425ad94eed67d059813511fe9ca55e73eb", "corpus_id": "2077908"}, "relationships": null}, {"id_": "schuster1997bidirectional", "type_": "citation", "bounding_boxes": [], "data": {"key": "schuster1997bidirectional", "bibitem_text": "M.~Schuster and K.~K. Paliwal. Bidirectional recurrent neural networks. \\em IEEE Transactions on Signal Processing, 45(11):2673--2681, 1997.", "paper_id": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85", "corpus_id": "18375389"}, "relationships": null}, {"id_": "yoshioka2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "yoshioka2015", "bibitem_text": "T.~Yoshioka, N.~Ito, M.~Delcroix, A.~Ogawa, K.~Kinoshita, M.~F.~C. Yu, W.~J. Fabian, M.~Espi, T.~Higuchi, S.~Araki, and T.~Nakatani. The ntt chime-3 system: Advances in speech enhancement and recognition for mobile multi-microphone devices. In \\em IEEE ASRU , 2015.", "paper_id": "0c73d7be1236683d18a54751e783d6cce36bfc35", "corpus_id": "31913713"}, "relationships": null}, {"id_": "mohamed2011", "type_": "citation", "bounding_boxes": [], "data": {"key": "mohamed2011", "bibitem_text": "A.~Mohamed, G.~Dahl, and G.~Hinton. Acoustic modeling using deep belief networks. \\em IEEE Transactions on Audio, Speech, and Language Processing, (99), 2011.", "paper_id": "d2b62f77cb2864e465aa60bca6c26bb1d2f84963", "corpus_id": "9530137"}, "relationships": null}, {"id_": "ko2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "ko2015", "bibitem_text": "T.~Ko, V.~Peddinti, D.~Povey, and S.~Khudanpur. Audio augmentation for speech recognition. In \\em Interspeech , 2015.", "paper_id": "66661a68dbf1d98d794fd025113b103683510303", "corpus_id": "7360763"}, "relationships": null}, {"id_": "robinson1996", "type_": "citation", "bounding_boxes": [], "data": {"key": "robinson1996", "bibitem_text": "T.~Robinson, M.~Hochberg, and S.~Renals. The use of recurrent neural networks in continuous speech recognition. pages 253--258, 1996.", "paper_id": "03bc854feaee144b54924b440eff02ed9082cc6b", "corpus_id": "8375725"}, "relationships": null}, {"id_": "graves2014", "type_": "citation", "bounding_boxes": [], "data": {"key": "graves2014", "bibitem_text": "A.~Graves and N.~Jaitly. Towards end-to-end speech recognition with recurrent neural networks. In \\em ICML , 2014.", "paper_id": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f", "corpus_id": "1166498"}, "relationships": null}, {"id_": "seide2011b", "type_": "citation", "bounding_boxes": [], "data": {"key": "seide2011b", "bibitem_text": "F.~Seide, G.~Li, and D.~Yu. Conversational speech transcription using context-dependent deep neural networks. In \\em Interspeech , pages 437--440, 2011.", "paper_id": "473f0739666af2791ad6592822118240ed968b70", "corpus_id": "398770"}, "relationships": null}, {"id_": "bengio2009curriculum", "type_": "citation", "bounding_boxes": [], "data": {"key": "bengio2009curriculum", "bibitem_text": "Y.~Bengio, J.~Louradour, R.~Collobert, and J.~Weston. Curriculum learning. In \\em International Conference on Machine Learning , 2009.", "paper_id": "8de174ab5419b9d3127695405efd079808e956e8", "corpus_id": "873046"}, "relationships": null}, {"id_": "dean2012largescale", "type_": "citation", "bounding_boxes": [], "data": {"key": "dean2012largescale", "bibitem_text": "J.~Dean, G.~S. Corrado, R.~Monga, K.~Chen, M.~Devin, Q.~Le, M.~Mao, M.~Ranzato, A.~Senior, P.~Tucker, K.~Yang, and A.~Ng. Large scale distributed deep networks. In \\em Advances in Neural Information Processing Systems 25 , 2012.", "paper_id": "3127190433230b3dc1abd0680bb58dced4bcd90e", "corpus_id": "372467"}, "relationships": null}, {"id_": "ioffe2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "ioffe2015", "bibitem_text": "C.~Szegedy and S.~Ioffe. Batch normalization: Accelerating deep network training by reducing internal covariate shift. abs/1502.03167, 2015. http://arxiv.org/abs/1502.03167.", "paper_id": "4d376d6978dad0374edfa6709c9556b42d3594d3", "corpus_id": "5808102"}, "relationships": null}, {"id_": "chilimbi2014adam", "type_": "citation", "bounding_boxes": [], "data": {"key": "chilimbi2014adam", "bibitem_text": "T.~Chilimbi, Y.~Suzue, J.~Apacible, and K.~Kalyanaraman. Project adam: Building an efficient and scalable deep learning training system. In \\em USENIX Symposium on Operating Systems Design and Implementation , 2014.", "paper_id": "e69c8b5df8a4178b1c8c7f154a761147a6f030be", "corpus_id": "2185117"}, "relationships": null}, {"id_": "dahl2011a", "type_": "citation", "bounding_boxes": [], "data": {"key": "dahl2011a", "bibitem_text": "G.~Dahl, D.~Yu, L.~Deng, and A.~Acero. Context-dependent pre-trained deep neural networks for large vocabulary speech recognition. \\em IEEE Transactions on Audio, Speech, and Language Processing, 2011.", "paper_id": "6658bbf68995731b2083195054ff45b4eca38b3a", "corpus_id": "14862572"}, "relationships": null}, {"id_": "sainath2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "sainath2015", "bibitem_text": "T.~Sainath, O.~Vinyals, A.~Senior, and H.~Sak. Convolutional, long short-term memory, fully connected deep neural networks. In \\em ICASSP , 2015.", "paper_id": "dec2ccce1ecb34bab02c42c2dd18cb468470adf8", "corpus_id": "898670"}, "relationships": null}, {"id_": "pascanu2012", "type_": "citation", "bounding_boxes": [], "data": {"key": "pascanu2012", "bibitem_text": "R.~Pascanu, T.~Mikolov, and Y.~Bengio. On the difficulty of training recurrent neural networks. abs/1211.5063, 2012. http://arxiv.org/abs/1211.5063.", "paper_id": "84069287da0a6b488b8c933f3cb5be759cb6237e", "corpus_id": "14650762"}, "relationships": null}, {"id_": "abdelhamid2012", "type_": "citation", "bounding_boxes": [], "data": {"key": "abdelhamid2012", "bibitem_text": "O.~Abdel-Hamid, A.-r. Mohamed, H.~Jang, and G.~Penn. Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition. In \\em ICASSP , 2012.", "paper_id": "9a9f4bf3bfe133e1c70f6b60654c238b677c66d0", "corpus_id": "10042024"}, "relationships": null}, {"id_": "sak2014b", "type_": "citation", "bounding_boxes": [], "data": {"key": "sak2014b", "bibitem_text": "H.~Sak, O.~Vinyals, G.~Heigold, A.~Senior, E.~McDermott, R.~Monga, and M.~Mao. Sequence discriminative distributed training of long shortterm memory recurrent neural networks. In \\em Interspeech , 2014.", "paper_id": "965c9aec5e68d49142c5af6a9f0a984f6c2c743a", "corpus_id": "28800623"}, "relationships": null}, {"id_": "sapp2008synth", "type_": "citation", "bounding_boxes": [], "data": {"key": "sapp2008synth", "bibitem_text": "B.~Sapp, A.~Saxena, and A.~Ng. A fast data collection and augmentation procedure for object recognition. In \\em AAAI Twenty-Third Conference on Artificial Intelligence , 2008.", "paper_id": "1f3a2cdbd1a27485bb76dd666f6fd3baf5bb1ab5", "corpus_id": "1817910"}, "relationships": null}, {"id_": "coates2013cotshpc", "type_": "citation", "bounding_boxes": [], "data": {"key": "coates2013cotshpc", "bibitem_text": "A.~Coates, B.~Huval, T.~Wang, D.~J. Wu, A.~Y. Ng, and B.~Catanzaro. Deep learning with COTS HPC . In \\em International Conference on Machine Learning , 2013.", "paper_id": "d1208ac421cf8ff67b27d93cd19ae42b8d596f95", "corpus_id": "8604637"}, "relationships": null}, {"id_": "hannun2014firstpass", "type_": "citation", "bounding_boxes": [], "data": {"key": "hannun2014firstpass", "bibitem_text": "A.~Y. Hannun, A.~L. Maas, D.~Jurafsky, and A.~Y. Ng. First-pass large vocabulary continuous speech recognition using bi-directional recurrent DNN s. abs/1408.2873, 2014. http://arxiv.org/abs/1408.2873.", "paper_id": "79d1e429c241d0aa47a2194246256a5bc79585bc", "corpus_id": "16783611"}, "relationships": null}, {"id_": "kapralove2014", "type_": "citation", "bounding_boxes": [], "data": {"key": "kapralove2014", "bibitem_text": "O.~Kapralova, J.~Alex, E.~Weinstein, P.~Moreno, and O.~Siohan. A big data approach to acoustic model training corpus selection. In \\em Interspeech , 2014.", "paper_id": "dd8a3b42d0b0785a4f30e096c8c3959ba1520d3d", "corpus_id": "5917427"}, "relationships": null}, {"id_": "sak2015", "type_": "citation", "bounding_boxes": [], "data": {"key": "sak2015", "bibitem_text": "H.~Sak, A.~Senior, K.~Rao, and F.~Beaufays. Fast and accurate recurrent neural network acoustic models for speech recognition. abs/1507.06947, 2015. http://arxiv.org/abs/1507.06947.", "paper_id": "9fca2af9a0e3f2c5c3ed47abb3ebd21b7265ac2b", "corpus_id": "11298362"}, "relationships": null}, {"id_": "hannun2014deepspeech", "type_": "citation", "bounding_boxes": [], "data": {"key": "hannun2014deepspeech", "bibitem_text": "A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger, S.~Satheesh, S.~Sengupta, A.~Coates, and A.~Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014. http://arxiv.org/abs/1412.5567.", "paper_id": "24741d280869ad9c60321f5ab6e5f01b7852507d", "corpus_id": "16979536"}, "relationships": null}, {"id_": "ModernGPU", "type_": "citation", "bounding_boxes": [], "data": {"key": "ModernGPU", "bibitem_text": "S.~Baxter. Modern GPU. https://nvlabs.github.io/moderngpu/."}, "relationships": null}, {"id_": "dahl2011", "type_": "citation", "bounding_boxes": [], "data": {"key": "dahl2011", "bibitem_text": "G.~Dahl, D.~Yu, and L.~Deng. Large vocabulary continuous speech recognition with context-dependent DBN-HMMs . In \\em Proc. ICASSP , 2011.", "paper_id": "2446e8f2012f23176ff602be633c0ed2b956d66c", "corpus_id": "6703261"}, "relationships": null}, {"id_": "heafield2013kenlm", "type_": "citation", "bounding_boxes": [], "data": {"key": "heafield2013kenlm", "bibitem_text": "K.~Heafield, I.~Pouzyrevsky, J.~H. Clark, and P.~Koehn. Scalable modified Kneser-Ney language model estimation. In \\em Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics , Sofia, Bulgaria, 8 2013.", "paper_id": "774e560a2cadcb84f4b1def7b152e5398b062efb", "corpus_id": "2561041"}, "relationships": null}, {"id_": "gales2009", "type_": "citation", "bounding_boxes": [], "data": {"key": "gales2009", "bibitem_text": "M.~J.~F. Gales, A.~Ragni, H.~Aldamarki, and C.~Gautier. Support vector machines for noise robust ASR . In \\em ASRU , pages 205--2010, 2009.", "paper_id": "a79469f93eb180f6b2227a8d511667028d1720cf", "corpus_id": "19022413"}, "relationships": null}, {"id_": "sainath2013cnn", "type_": "citation", "bounding_boxes": [], "data": {"key": "sainath2013cnn", "bibitem_text": "T.~N. Sainath, A.~rahman Mohamed, B.~Kingsbury, and B.~Ramabhadran. Deep convolutional neural networks for LVCSR . In \\em ICASSP , 2013.", "paper_id": "57a5fa22f10ce6ccf27286f74a050d2dac037e06", "corpus_id": "13816461"}, "relationships": null}, {"id_": "graves2006", "type_": "citation", "bounding_boxes": [], "data": {"key": "graves2006", "bibitem_text": "A.~Graves, S.~Fern\\'a ndez, F.~Gomez, and J.~Schmidhuber. Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In \\em ICML , pages 369--376. ACM, 2006.", "paper_id": "96494e722f58705fa20302fe6179d483f52705b4", "corpus_id": "9901844"}, "relationships": null}, {"id_": "vesely2013", "type_": "citation", "bounding_boxes": [], "data": {"key": "vesely2013", "bibitem_text": "K.~Vesely, A.~Ghoshal, L.~Burget, and D.~Povey. Sequence-discriminative training of deep neural networks. In \\em Interspeech , 2013.", "paper_id": "b48168acba4a6ca33ad0f11bbf1c7d8106333822", "corpus_id": "2827512"}, "relationships": null}]}